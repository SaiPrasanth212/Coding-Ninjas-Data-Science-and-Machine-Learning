{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwAAPrdNFoH0"
   },
   "source": [
    "Downloading the [Zip file](http://www.manythings.org/anki/fra-eng.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDBptzV8z6Lj",
    "outputId": "6758a032-30ed-4af2-c741-aa059f42e129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-07 10:23:06--  http://www.manythings.org/anki/fra-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 172.67.173.198, 104.24.109.196, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6129887 (5.8M) [application/zip]\n",
      "Saving to: ‘fra-eng.zip’\n",
      "\n",
      "fra-eng.zip         100%[===================>]   5.85M  9.29MB/s    in 0.6s    \n",
      "\n",
      "2021-01-07 10:23:07 (9.29 MB/s) - ‘fra-eng.zip’ saved [6129887/6129887]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.manythings.org/anki/fra-eng.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqmsUr54GM8M"
   },
   "source": [
    "**Extracting the Zip file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "R7_XKmpIJFT1"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip = zipfile.ZipFile('fra-eng.zip')\n",
    "zip.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JIkRGU6GTrj"
   },
   "source": [
    "**Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "F1NLrlQkMHhH"
   },
   "outputs": [],
   "source": [
    "import string,re\n",
    "from unicodedata import normalize\n",
    "from numpy import array,argmax\n",
    "from pickle import load,dump\n",
    "from numpy.random import rand,shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dvlzRVWJGeq8"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import LSTM,Dense,Embedding,RepeatVector,TimeDistributed\n",
    "from nltk.translate.bleu_score import SmoothingFunction,corpus_bleu\n",
    "smoothie = SmoothingFunction().method4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Di1MTtIJugr"
   },
   "source": [
    "**Loading the file and reading the content of the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "p1uiIFmaLbZg"
   },
   "outputs": [],
   "source": [
    "# load file into memory\n",
    "def load_file(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ6vhjhDJ5jy"
   },
   "source": [
    "**Splitting the sentence into pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QV6559a1LvQI"
   },
   "outputs": [],
   "source": [
    "# split a loaded document into sentences\n",
    "def splitting_sentence(doc):\n",
    "\tsentences = doc.strip().split('\\n')\n",
    "\tpairs = [sentence.split('\\t') for sentence in  sentences]\n",
    "\treturn pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc2F_iwDKCAC"
   },
   "source": [
    "**Cleaning the pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2p-ZO41bL3U3"
   },
   "outputs": [],
   "source": [
    "# cleaning a list of sentences and creating pairs\n",
    "\n",
    "def clean_pairs(sentences):\n",
    "\tcleaned = list()\n",
    " \n",
    "\t# preparing regex for char filtering\n",
    "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "\n",
    "\t# preparing translation table for removing punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "  # iterating over each pair\n",
    "\tfor pair in sentences:\n",
    "\t\tclean_pair = list()\n",
    "  \n",
    "\t\tfor sentence in pair:\n",
    "\t\t\t# normalizing unicode characters\n",
    "\t\t\tsentence = normalize('NFD', sentence).encode('ascii', 'ignore')\n",
    "\t\t\tsentence = sentence.decode('UTF-8')\n",
    "\t\t\t# tokenizing on white space\n",
    "\t\t\tsentence = sentence.split()\n",
    "\t\t\t# converting to lowercase\n",
    "\t\t\tsentence = [word.lower() for word in sentence]\n",
    "\t\t\t# removing punctuation from each token\n",
    "\t\t\tsentence = [word.translate(table) for word in sentence]\n",
    "\t\t\t# removing non-printable chars form each token\n",
    "\t\t\tsentence = [re_print.sub('', w) for w in sentence]\n",
    "\t\t\t# removing tokens with numbers in them\n",
    "\t\t\tsentence = [word for word in sentence if word.isalpha()]\n",
    "\t\t\t# storing as string\n",
    "\t\t\tclean_pair.append(' '.join(sentence))\n",
    "\t\tcleaned.append(clean_pair)\n",
    "\treturn array(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfpzMDIDMIvC"
   },
   "source": [
    "**Saving the Cleaned data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ovtlpsp3MVU_"
   },
   "outputs": [],
   "source": [
    "def saving_clean_data(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint(filename,': Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3RLnKIVMO5J"
   },
   "source": [
    "**Saving data in .pkl format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tkoxnpbMjLn",
    "outputId": "4d699ce9-a303-4fba-f01c-ab8603e5ee95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english-french.pkl : Saved\n",
      "English --> French\n",
      "go --> va\n",
      "hi --> salut\n",
      "hi --> salut\n",
      "run --> cours\n",
      "run --> courez\n",
      "who --> qui\n",
      "wow --> ca alors\n",
      "fire --> au feu\n",
      "help --> a laide\n",
      "jump --> saute\n",
      "stop --> ca suffit\n",
      "stop --> stop\n",
      "stop --> arretetoi\n",
      "wait --> attends\n",
      "wait --> attendez\n",
      "go on --> poursuis\n",
      "go on --> continuez\n",
      "go on --> poursuivez\n",
      "hello --> bonjour\n",
      "hello --> salut\n",
      "i see --> je comprends\n",
      "i try --> jessaye\n",
      "i won --> jai gagne\n",
      "i won --> je lai emporte\n",
      "i won --> jai gagne\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "filename = 'fra.txt'\n",
    "doc = load_file(filename)\n",
    "\n",
    "# split into english-french pairs\n",
    "pairs = splitting_sentence(doc)\n",
    "\n",
    "# clean sentences\n",
    "clean_pairs = clean_pairs(pairs)\n",
    "\n",
    "# save clean pairs to file\n",
    "saving_clean_data(clean_pairs, 'english-french.pkl')\n",
    "\n",
    "print('English','-->',\"French\")\n",
    "# spot check\n",
    "for i in range(25):\n",
    "\tprint(clean_pairs[i,0],'-->',clean_pairs[i,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq5SVqTtcQtS"
   },
   "source": [
    "**Loading the cleaned data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L5oB73alcVRO"
   },
   "outputs": [],
   "source": [
    "# load a clean dataset\n",
    "def loading_cleaned_data(filename):\n",
    "\treturn load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORWdTFwKPh7G",
    "outputId": "8eef7755-b8e7-42fa-f77a-3e0ca06b35c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179904, 3)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data = loading_cleaned_data('english-french.pkl')\n",
    "print(data.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5RbRHzlL_oF"
   },
   "source": [
    "**Scaling of data** \n",
    "\n",
    "**Size**\n",
    "\n",
    "1.Dataset - 20000\n",
    "\n",
    "2.Training - 18000\n",
    "\n",
    "3.Testing - 2000   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjGXDVkDcpAy",
    "outputId": "1fff4400-c7a2-4374-8b51-23fe1b2f83d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english-french-both.pkl : Saved\n",
      "english-french-train.pkl : Saved\n",
      "english-french-test.pkl : Saved\n"
     ]
    }
   ],
   "source": [
    "# reducing dataset size (scaling) \n",
    "\n",
    "new_data_size = 20000\n",
    "dataset = data[:new_data_size, :]\n",
    "\n",
    "# randomly shuffling the dataset to get proper training and testing data\n",
    "shuffle(dataset)\n",
    "\n",
    "# splitting into training and testing (90%-10%)\n",
    "train, test = dataset[:18000], dataset[18000:]\n",
    "\n",
    "# saving the cleaned data,train data and test data \n",
    "saving_clean_data(dataset, 'english-french-both.pkl')\n",
    "saving_clean_data(train, 'english-french-train.pkl')\n",
    "saving_clean_data(test, 'english-french-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "h-_XKg-UMojw"
   },
   "outputs": [],
   "source": [
    "# loading datasets and saving it into variables\n",
    "dataset = loading_cleaned_data('english-french-both.pkl')\n",
    "train = loading_cleaned_data('english-french-train.pkl')\n",
    "test = loading_cleaned_data('english-french-test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avp8Q0-xdaUj"
   },
   "source": [
    "**Creating a tokenizer for the lines and finding the maximum length phrase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wLD8OFAIPJUf"
   },
   "outputs": [],
   "source": [
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "\ttokenizer = Tokenizer()\n",
    "\ttokenizer.fit_on_texts(lines)\n",
    "\treturn tokenizer\n",
    "\n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "\treturn max(len(line.split()) for line in lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKvmKQxWeRPQ"
   },
   "source": [
    "**Size of English & French vocabulary and their max phrase length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDijv11iQ6CX",
    "outputId": "f33fe371-70a9-411b-aedd-d63f8e3fbe74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 3460\n",
      "English Max Length: 5\n",
      "French Vocabulary Size: 6922\n",
      "French Max Length: 11\n"
     ]
    }
   ],
   "source": [
    "# preparing the english tokenizer\n",
    "\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\n",
    "\n",
    "# preparing the french tokenizer\n",
    "\n",
    "fra_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "fra_length = max_length(dataset[:, 1])\n",
    "print('French Vocabulary Size: %d' % fra_vocab_size)\n",
    "print('French Max Length: %d' % (fra_length))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3k5O2spejJH"
   },
   "source": [
    "**Encoding to integers and padding to the maximum phrase length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8WECbBTNRG5W"
   },
   "outputs": [],
   "source": [
    "# Input and Output sequence must be encoded to integers and padded to the maximum phrase length\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "\t# integer encode sequences\n",
    "\tx = tokenizer.texts_to_sequences(lines)\n",
    "\t# pad sequences with 0 values\n",
    "\tx = pad_sequences(x, maxlen=length, padding='post')\n",
    "\treturn x\n",
    "\n",
    "# One hot encoding to max phrase length\n",
    "def one_hot_encoding(sequences, vocab_size):\n",
    "\ty_1 = list()\n",
    "\tfor sequence in sequences:\n",
    "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "\t\ty_1.append(encoded)\n",
    "\ty = array(y_1)\n",
    "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "\treturn y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dvj7nZWf8c-"
   },
   "source": [
    "**Training and Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nj7j2bIWf78M"
   },
   "outputs": [],
   "source": [
    "# preparing training data\n",
    "trainX = encode_sequences(fra_tokenizer, fra_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "trainY = one_hot_encoding(trainY, eng_vocab_size)\n",
    "\n",
    "# prepare testing data\n",
    "testX = encode_sequences(fra_tokenizer, fra_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer,eng_length, test[:, 0])\n",
    "testY = one_hot_encoding(testY, eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8xr_mwyFdRD",
    "outputId": "c4e25354-f84b-4886-c5f7-0d3f6a53ec5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (18000, 11) (18000, 5, 3460)\n",
      "testing size: (2000, 11) (2000, 5, 3460)\n"
     ]
    }
   ],
   "source": [
    "print('training size:',trainX.shape,trainY.shape)\n",
    "print('testing size:',testX.shape,testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bs628M3JgpLZ"
   },
   "source": [
    "**Building the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pBlM7AzcR-U_"
   },
   "outputs": [],
   "source": [
    "def model_building(source_vocab, target_vocab, source_len, target_len, units):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Embedding(source_vocab, units, input_length=source_len, mask_zero=True))\n",
    "\tmodel.add(LSTM(units))\n",
    "\tmodel.add(RepeatVector(target_len))\n",
    "\tmodel.add(LSTM(units, return_sequences=True))\n",
    "\tmodel.add(TimeDistributed(Dense(target_vocab, activation='softmax')))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HexQi4N7iLln"
   },
   "source": [
    "**Defining and Compiling the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wOrjJUy8SECu"
   },
   "outputs": [],
   "source": [
    "model = model_building(fra_vocab_size, eng_vocab_size, fra_length, eng_length, 512)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3ovCukmiRzW"
   },
   "source": [
    "**Model Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwb8ibuDSUvW",
    "outputId": "cb158472-223e-4e30-a233-5744b7c2460d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 11, 512)           3544064   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 512)            2099200   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 5, 3460)           1774980   \n",
      "=================================================================\n",
      "Total params: 9,517,444\n",
      "Trainable params: 9,517,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "d3_4Jn4RkNU9"
   },
   "outputs": [],
   "source": [
    "# Stop model if accuracy of the model doesn't changes by more than 0.01 \n",
    "# Patience = 5 : After each 5 epochs if no improvement is there then training will be stopped.\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_acc',patience= 5,min_delta=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VP_QQwGiZrN"
   },
   "source": [
    "**Fitting the model**\n",
    "\n",
    "1.Epochs = 50\n",
    "\n",
    "2.Batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BI6ioDuaS57H",
    "outputId": "c166b7d8-49b9-4416-927a-7722c7350d54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "720/720 - 35s - loss: 3.7328 - acc: 0.4385 - val_loss: 3.1504 - val_acc: 0.4987\n",
      "Epoch 2/50\n",
      "720/720 - 24s - loss: 2.7811 - acc: 0.5426 - val_loss: 2.5641 - val_acc: 0.5814\n",
      "Epoch 3/50\n",
      "720/720 - 24s - loss: 2.1818 - acc: 0.6056 - val_loss: 2.2248 - val_acc: 0.6138\n",
      "Epoch 4/50\n",
      "720/720 - 25s - loss: 1.7135 - acc: 0.6572 - val_loss: 2.0067 - val_acc: 0.6435\n",
      "Epoch 5/50\n",
      "720/720 - 24s - loss: 1.3279 - acc: 0.7101 - val_loss: 1.8262 - val_acc: 0.6674\n",
      "Epoch 6/50\n",
      "720/720 - 24s - loss: 0.9954 - acc: 0.7662 - val_loss: 1.7155 - val_acc: 0.6913\n",
      "Epoch 7/50\n",
      "720/720 - 25s - loss: 0.7395 - acc: 0.8162 - val_loss: 1.6456 - val_acc: 0.7129\n",
      "Epoch 8/50\n",
      "720/720 - 25s - loss: 0.5407 - acc: 0.8595 - val_loss: 1.6244 - val_acc: 0.7219\n",
      "Epoch 9/50\n",
      "720/720 - 25s - loss: 0.4048 - acc: 0.8923 - val_loss: 1.6326 - val_acc: 0.7295\n",
      "Epoch 10/50\n",
      "720/720 - 25s - loss: 0.3119 - acc: 0.9159 - val_loss: 1.6253 - val_acc: 0.7328\n",
      "Epoch 11/50\n",
      "720/720 - 25s - loss: 0.2497 - acc: 0.9304 - val_loss: 1.6645 - val_acc: 0.7293\n",
      "Epoch 12/50\n",
      "720/720 - 25s - loss: 0.2136 - acc: 0.9379 - val_loss: 1.6664 - val_acc: 0.7370\n",
      "Epoch 13/50\n",
      "720/720 - 25s - loss: 0.1917 - acc: 0.9434 - val_loss: 1.6865 - val_acc: 0.7379\n",
      "Epoch 14/50\n",
      "720/720 - 24s - loss: 0.1760 - acc: 0.9457 - val_loss: 1.7025 - val_acc: 0.7387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd5a41055f8>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(trainX, trainY, epochs= 50, batch_size=25, validation_data=(testX, testY), verbose=2,callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PamgrtO1tc81"
   },
   "source": [
    "**Evaluating model and calculating BLEU Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jpeIlnvNTyK"
   },
   "source": [
    "Evaluation involves two steps: \n",
    "\n",
    "1.Generating a translated output sequence, and \n",
    "\n",
    "2.then repeating this process for many input examples and summarizing the skill of the model across multiple cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vjz4ERSYT1Df"
   },
   "outputs": [],
   "source": [
    "# mapping integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == integer:\n",
    "\t\t\treturn word\n",
    "\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "XZV4Qm51TxdH"
   },
   "outputs": [],
   "source": [
    "# generating target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "\tprediction = model.predict(source, verbose=0)[0]\n",
    "\tintegers = [argmax(vector) for vector in prediction]\n",
    "\ttarget = list()\n",
    "\tfor i in integers:\n",
    "\t\tword = word_for_id(i, tokenizer)\n",
    "\t\tif word is None:\n",
    "\t\t\tbreak\n",
    "\t\ttarget.append(word)\n",
    "\treturn ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "_pHVBAejXOA1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# evaluating the skill of the model\n",
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "  \n",
    "  # Creating empty lists for actual phrases(French) and predicted phrases(English) \n",
    "  actual,predicted = list(),list()\n",
    "  a,b,c = list(),list(),list()\n",
    "  for i,source in enumerate(sources):\n",
    "\n",
    "    # reshaping to the required size\n",
    "    source = source.reshape((1, source.shape[0]))\n",
    "\n",
    "    # predicting for the english tokenizer\n",
    "    translation = predict_sequence(model, eng_tokenizer, source)\n",
    "    # raw_dataset = raw_dataset[i].split(' ') \n",
    "    # print(raw_dataset[i][1])\n",
    "\n",
    "    raw_src,raw_target = raw_dataset[i][1],raw_dataset[i][0]\n",
    "    \n",
    "    # First 10 Predictions\n",
    "    if i <= 10:\n",
    "      print('source = ',raw_src,'<--->', ' target = ',raw_target,'<--->','  predicted = ',translation)\n",
    "\n",
    "    actual.append([raw_target.split()])\n",
    "    predicted.append(translation.split())\n",
    "  \n",
    "  # calculating BLEU score\n",
    "  print('-------------------------------------------')\n",
    "  print('BLEU Score :')\n",
    "  print('BLEU score-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0),smoothing_function=smoothie,auto_reweigh=False))\n",
    "  print('BLEU score-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0),smoothing_function=smoothie,auto_reweigh=False))\n",
    "  print('BLEU score-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0),smoothing_function=smoothie,auto_reweigh=False))\n",
    "  print('BLEU score-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25),smoothing_function=smoothie,auto_reweigh=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnrScoRlPafY"
   },
   "source": [
    "**Evaluating Model on training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q42oWYQuWhSw",
    "outputId": "90053f9b-4d1d-4300-d37d-75067581ab39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source =  je suis divorce <--->  target =  i am divorced <--->   predicted =  im divorced\n",
      "source =  la vie nest pas facile <--->  target =  life aint easy <--->   predicted =  lifes not easy\n",
      "source =  tom est finalement parti <--->  target =  tom finally left <--->   predicted =  tom finally left\n",
      "source =  tom ecrit bien <--->  target =  tom writes well <--->   predicted =  tom writes well\n",
      "source =  je ne laime pas <--->  target =  i dont like him <--->   predicted =  i dont like her\n",
      "source =  attache tes chaussures <--->  target =  tie your shoes <--->   predicted =  tie your shoes\n",
      "source =  appelons tom <--->  target =  lets call tom <--->   predicted =  lets call tom\n",
      "source =  fermez la boite <--->  target =  close the box <--->   predicted =  close the box\n",
      "source =  cest enorme <--->  target =  this is huge <--->   predicted =  this is huge\n",
      "source =  donneznous une seconde <--->  target =  give us a second <--->   predicted =  give us a second\n",
      "source =  jetais horrifiee <--->  target =  i was horrified <--->   predicted =  i was horrified\n",
      "-------------------------------------------\n",
      "BLEU Score :\n",
      "BLEU score-1: 0.948733\n",
      "BLEU score-2: 0.930221\n",
      "BLEU score-3: 0.881637\n",
      "BLEU score-4: 0.661279\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,eng_tokenizer,trainX,train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgxS1flZPjNJ"
   },
   "source": [
    "**Evaluating Model on testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIsBhu9N5wfx",
    "outputId": "a45d7f83-50f1-49e6-c081-4ea9026ad9c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source =  ce sont des melons <--->  target =  they are melons <--->   predicted =  theyre garbage\n",
      "source =  les jumeaux sourirent <--->  target =  the twins smiled <--->   predicted =  the is fell\n",
      "source =  elle tirait la langue <--->  target =  she was panting <--->   predicted =  she stood him\n",
      "source =  je me suis trompe sur tom <--->  target =  i misjudged tom <--->   predicted =  i got at tom\n",
      "source =  que ressenstu <--->  target =  how does it feel <--->   predicted =  what do you\n",
      "source =  cest un soulagement <--->  target =  its a relief <--->   predicted =  thats a relief\n",
      "source =  vous pouvez me lacher <--->  target =  can you skip me <--->   predicted =  can you skip me\n",
      "source =  ce sont des amateurs <--->  target =  theyre amateurs <--->   predicted =  theyre garbage\n",
      "source =  je suis trop petit <--->  target =  i am too short <--->   predicted =  im too too\n",
      "source =  ils ont termine <--->  target =  theyre done <--->   predicted =  theyre done\n",
      "source =  nous sommes engagees <--->  target =  were committed <--->   predicted =  were canadians\n",
      "-------------------------------------------\n",
      "BLEU Score :\n",
      "BLEU score-1: 0.645399\n",
      "BLEU score-2: 0.548542\n",
      "BLEU score-3: 0.488032\n",
      "BLEU score-4: 0.303227\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, eng_tokenizer, testX, test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Machine Translation French-English.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
